"""
AWS Daily Digest â€” é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ Lambda

æ¯é€±æœˆæ›œ 09:00 JSTï¼ˆUTC 00:00ï¼‰ã«å®Ÿè¡Œã—:
  1. CloudWatch Metrics ã‹ã‚‰ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ Lambda ã®éå»7æ—¥åˆ†ã®å®Ÿè¡Œãƒ‡ãƒ¼ã‚¿ã‚’åé›†
  2. CloudWatch Logs Insights ã‹ã‚‰ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãƒ­ã‚°ã®è¨˜äº‹æ•°ã‚’é›†è¨ˆ
  3. CloudWatch Logs Insights ã‹ã‚‰ Online Evaluation ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆï¼ˆEVAL_LOG_GROUP è¨­å®šæ¸ˆã¿ã®å ´åˆï¼‰
  4. Bedrock InvokeModel ã§ Slack ç”¨ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
  5. Slack ã«æŠ•ç¨¿
"""

import json
import logging
import os
import time
from datetime import datetime, timedelta, timezone

import boto3
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError

logger = logging.getLogger()
logger.setLevel(logging.INFO)

SLACK_BOT_TOKEN       = os.environ["SLACK_BOT_TOKEN"]
SLACK_CHANNEL_ID      = os.environ["SLACK_CHANNEL_ID"]
HANDLER_FUNCTION_NAME = os.environ["HANDLER_FUNCTION_NAME"]
EVAL_LOG_GROUP        = os.environ.get("EVAL_LOG_GROUP", "")   # Online Evaluation è¨­å®šå¾Œã«è¿½åŠ 
REPORT_MODEL_ID       = os.environ["REPORT_MODEL_ID"]

cw           = boto3.client("cloudwatch")
logs_client  = boto3.client("logs")
bedrock      = boto3.client("bedrock-runtime")
slack_client = WebClient(token=SLACK_BOT_TOKEN)

REPORT_DAYS           = 7
LOGS_INSIGHTS_TIMEOUT = 60  # seconds


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. CloudWatch Metricsï¼ˆLambda ã®æ¨™æº–ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _get_lambda_metric(metric_name: str, stat: str, start: datetime, end: datetime) -> float:
    """AWS/Lambda åå‰ç©ºé–“ã‹ã‚‰å˜ä¸€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ã™ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ãªã—æ™‚ã¯ 0.0 ã‚’è¿”ã™ã€‚"""
    resp = cw.get_metric_statistics(
        Namespace="AWS/Lambda",
        MetricName=metric_name,
        Dimensions=[{"Name": "FunctionName", "Value": HANDLER_FUNCTION_NAME}],
        StartTime=start,
        EndTime=end,
        Period=int((end - start).total_seconds()),
        Statistics=[stat],
    )
    datapoints = resp.get("Datapoints", [])
    return float(datapoints[0][stat]) if datapoints else 0.0


def collect_lambda_metrics(start: datetime, end: datetime) -> dict:
    """ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ Lambda ã®å®Ÿè¡Œå›æ•°ãƒ»ã‚¨ãƒ©ãƒ¼æ•°ãƒ»å®Ÿè¡Œæ™‚é–“ã‚’åé›†ã™ã‚‹ã€‚"""
    return {
        "invocations":     int(_get_lambda_metric("Invocations", "Sum",     start, end)),
        "errors":          int(_get_lambda_metric("Errors",      "Sum",     start, end)),
        "duration_avg_ms": round(_get_lambda_metric("Duration",  "Average", start, end)),
        "duration_max_ms": round(_get_lambda_metric("Duration",  "Maximum", start, end)),
        "expected":        REPORT_DAYS * 2,  # morning Ã— 7 + noon Ã— 7
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. CloudWatch Logs Insightsï¼ˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãƒ­ã‚°ã‹ã‚‰è¨˜äº‹æ•°ã‚’é›†è¨ˆï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _run_logs_query(log_group: str, query: str, start: datetime, end: datetime) -> list[dict]:
    """
    Logs Insights ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¦ãƒãƒ¼ãƒªãƒ³ã‚°ã—ã€çµæœã‚’ [{field: value}, ...] ã®ãƒªã‚¹ãƒˆã§è¿”ã™ã€‚
    ãƒ­ã‚°ãƒ«ãƒ¼ãƒ—ãŒå­˜åœ¨ã—ãªã„å ´åˆãƒ»ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    """
    try:
        resp = logs_client.start_query(
            logGroupName=log_group,
            startTime=int(start.timestamp()),
            endTime=int(end.timestamp()),
            queryString=query,
        )
    except logs_client.exceptions.ResourceNotFoundException:
        logger.warning("ãƒ­ã‚°ãƒ«ãƒ¼ãƒ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“: %s", log_group)
        return []

    query_id = resp["queryId"]
    deadline = time.time() + LOGS_INSIGHTS_TIMEOUT

    while time.time() < deadline:
        result = logs_client.get_query_results(queryId=query_id)
        status = result["status"]
        if status == "Complete":
            return [
                {f["field"]: f["value"] for f in row}
                for row in result.get("results", [])
            ]
        if status in ("Failed", "Cancelled"):
            logger.warning("Logs Insights ã‚¯ã‚¨ãƒªå¤±æ•—: status=%s log_group=%s", status, log_group)
            return []
        time.sleep(2)

    logger.warning("Logs Insights ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: %s", log_group)
    try:
        logs_client.stop_query(queryId=query_id)
    except Exception:
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¤å®šç›´å¾Œã«ã‚¯ã‚¨ãƒªãŒå®Œäº†ã—ãŸå ´åˆã€stop_query ã¯ InvalidParameterException ã‚’è¿”ã™
        pass
    return []


def collect_article_stats(start: datetime, end: datetime) -> dict:
    """ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ Lambda ã®ãƒ­ã‚°ã‹ã‚‰è¨˜äº‹æ•°ã¨ãƒ¢ãƒ¼ãƒ‰åˆ¥å®Ÿè¡Œæ•°ã‚’é›†è¨ˆã™ã‚‹ã€‚"""
    log_group = f"/aws/lambda/{HANDLER_FUNCTION_NAME}"

    # handler.py ã® logger.info("å–å¾—è¨˜äº‹æ•°: %d ä»¶", ...) ã‚’é›†è¨ˆ
    article_query = """
fields @message
| filter @message like /å–å¾—è¨˜äº‹æ•°/
| parse @message /å–å¾—è¨˜äº‹æ•°: (?<count>\\d+) ä»¶/
| stats
    sum(count) as total_articles,
    avg(count) as avg_articles,
    min(count) as min_articles,
    max(count) as max_articles,
    count(*)   as runs
""".strip()

    # handler.py ã® logger.info("handler é–‹å§‹: mode=%s", ...) ã‹ã‚‰ãƒ¢ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    mode_query = """
fields @message
| filter @message like /handler é–‹å§‹/
| parse @message /mode=(?<mode>\\S+)/
| stats count(*) as runs by mode
""".strip()

    article_rows = _run_logs_query(log_group, article_query, start, end)
    mode_rows    = _run_logs_query(log_group, mode_query,    start, end)

    result: dict = {
        "total_articles": 0,
        "avg_articles":   0.0,
        "min_articles":   0,
        "max_articles":   0,
        "runs":           0,
        "by_mode":        {},
    }

    if article_rows:
        row = article_rows[0]
        result.update({
            "total_articles": int(float(row.get("total_articles", 0))),
            "avg_articles":   round(float(row.get("avg_articles",   0)), 1),
            "min_articles":   int(float(row.get("min_articles",   0))),
            "max_articles":   int(float(row.get("max_articles",   0))),
            "runs":           int(float(row.get("runs",           0))),
        })

    for r in mode_rows:
        mode = r.get("mode", "unknown")
        result["by_mode"][mode] = int(float(r.get("runs", 0)))

    return result


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. Online Evaluation ã‚¹ã‚³ã‚¢ï¼ˆEVAL_LOG_GROUP è¨­å®šæ™‚ã®ã¿ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def collect_eval_scores(start: datetime, end: datetime) -> list[dict]:
    """
    AgentCore Online Evaluation ã®çµæœãƒ­ã‚°ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆã™ã‚‹ã€‚
    EVAL_LOG_GROUP ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã®å ´åˆã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    """
    if not EVAL_LOG_GROUP:
        return []

    query = """
fields score, evaluatorName
| filter ispresent(score)
| stats
    avg(score) as avg_score,
    min(score) as min_score,
    max(score) as max_score,
    count(*)   as count
    by evaluatorName
| sort evaluatorName
""".strip()

    rows = _run_logs_query(EVAL_LOG_GROUP, query, start, end)
    return [
        {
            "evaluator": r.get("evaluatorName", ""),
            "avg_score": round(float(r.get("avg_score", 0)), 3),
            "min_score": round(float(r.get("min_score", 0)), 3),
            "max_score": round(float(r.get("max_score", 0)), 3),
            "count":     int(float(r.get("count", 0))),
        }
        for r in rows
    ]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Bedrock InvokeModel ã§ Slack ç”¨ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def format_with_llm(raw_data: dict, period_label: str) -> str:
    """åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ Claude ã«æ¸¡ã—ã¦ Slack mrkdwn å½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    prompt = f"""ä»¥ä¸‹ã¯AWS Digest Agentã®é‹ç”¨ãƒ‡ãƒ¼ã‚¿ã§ã™ï¼ˆ{period_label}ï¼‰ã€‚
ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’Slackã®mrkdwnå½¢å¼ã§é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦æ•´å½¢ã—ã¦ãã ã•ã„ã€‚

{json.dumps(raw_data, ensure_ascii=False, indent=2)}

å‡ºåŠ›ãƒ«ãƒ¼ãƒ«:
- Slack mrkdwn å½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿å‡ºåŠ›ã™ã‚‹ï¼ˆå‰ç½®ããƒ»å¾Œæ›¸ãä¸è¦ï¼‰
- ãƒ˜ãƒƒãƒ€ãƒ¼ã« *å¤ªå­—* ã‚’ä½¿ã„ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åŒºåˆ‡ã‚‹
- çµµæ–‡å­—ã§è¦–èªæ€§ã‚’ä¸Šã’ã‚‹
- lambda_metrics.invocations < lambda_metrics.expected ã®å ´åˆ âš ï¸ ã§å®Ÿè¡Œæ¼ã‚Œã‚’è­¦å‘Šã™ã‚‹
- lambda_metrics.errors > 0 ã®å ´åˆ ğŸ”´ ã§è­¦å‘Šã—èª¿æŸ»ã‚’ä¿ƒã™
- duration ã¯ ms ã‹ã‚‰ç§’ã«å¤‰æ›ã—ã¦è¡¨ç¤ºã™ã‚‹ï¼ˆä¾‹: 47,230ms â†’ 47.2ç§’ï¼‰
- eval_scores ãŒã‚ã‚‹å ´åˆ: avg_score >= 0.8 â†’ âœ… è‰¯å¥½ã€0.6ã€œ0.8 â†’ âš ï¸ è¦æ³¨è¦–ã€< 0.6 â†’ ğŸ”´ è¦æ”¹å–„
- eval_scores ãŒç©ºã®å ´åˆ: ã€Œè©•ä¾¡ã‚¹ã‚³ã‚¢: æœªè¨­å®šï¼ˆOnline Evaluation è¨­å®šå¾Œã«åæ˜ ã•ã‚Œã¾ã™ï¼‰ã€ã¨è¨˜è¼‰ã™ã‚‹
""".strip()

    response = bedrock.invoke_model(
        modelId=REPORT_MODEL_ID,
        contentType="application/json",
        accept="application/json",
        body=json.dumps({
            "anthropic_version": "bedrock-2023-05-31",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 1200,
        }),
    )
    return json.loads(response["body"].read())["content"][0]["text"]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Lambda ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def handler(event, context):
    jst       = timezone(timedelta(hours=9))
    now_jst   = datetime.now(jst)
    end_utc   = datetime.now(timezone.utc)
    start_utc = end_utc - timedelta(days=REPORT_DAYS)

    period_label = (
        f"{(now_jst - timedelta(days=REPORT_DAYS)).strftime('%m/%d')}ã€œ"
        f"{now_jst.strftime('%m/%d')}"
    )
    logger.info("é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆé–‹å§‹: %s", period_label)

    raw_data = {
        "period":         period_label,
        "lambda_metrics": collect_lambda_metrics(start_utc, end_utc),
        "article_stats":  collect_article_stats(start_utc, end_utc),
        "eval_scores":    collect_eval_scores(start_utc, end_utc),
    }
    logger.info("ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: %s", json.dumps(raw_data, ensure_ascii=False))

    slack_text = format_with_llm(raw_data, period_label)
    logger.info("LLMãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®Œäº†")

    try:
        slack_client.chat_postMessage(
            channel=SLACK_CHANNEL_ID,
            text=slack_text,
            mrkdwn=True,
        )
        logger.info("Slack æŠ•ç¨¿å®Œäº†")
    except SlackApiError as e:
        logger.error("Slack æŠ•ç¨¿å¤±æ•—: %s", e.response["error"])
        raise

    return {"statusCode": 200, "period": period_label}
